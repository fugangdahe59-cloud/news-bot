import os
import feedparser
import asyncio
import datetime
import discord
import random
import requests
import openai
from bs4 import BeautifulSoup

# ===== ç’°å¢ƒå¤‰æ•° =====
WEBHOOK_IT = os.getenv("WEBHOOK_IT")
WEBHOOK_BUSINESS = os.getenv("WEBHOOK_BUSINESS")
WEBHOOK_IT_SUMMARY = os.getenv("WEBHOOK_IT_SUMMARY")
WEBHOOK_BUSINESS_SUMMARY = os.getenv("WEBHOOK_BUSINESS_SUMMARY")
WEBHOOK_DAILY_REVIEW = os.getenv("WEBHOOK_DAILY_REVIEW")
openai.api_key = os.getenv("OPENAI_API_KEY")

# ===== åˆ¶é™ =====
AI_LIMIT_PER_HOUR = 10
ai_calls_this_hour = 0
last_reset_hour = -1

summary_cache = {}

FEEDS = {
    "IT": "https://news.yahoo.co.jp/rss/topics/it.xml",
    "BUSINESS": "https://news.yahoo.co.jp/rss/topics/business.xml"
}

# ===== JSTæ™‚é–“ =====
def now_jst():
    return datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))

# ===== Webhooké€ä¿¡ =====
def send_webhook(url, content):
    if not url:
        return
    try:
        webhook = discord.SyncWebhook.from_url(url)
        webhook.send(content)
        print("[OK] æŠ•ç¨¿:", content[:80])
    except Exception as e:
        print("[ERROR]", e)

# ===== è¨˜äº‹æœ¬æ–‡å–å¾— =====
def fetch_article_text(url):
    try:
        r = requests.get(url, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        paragraphs = soup.find_all("p")
        text = "\n".join(p.get_text() for p in paragraphs)
        return text[:4000]
    except:
        return ""

# ===== AIè¦ç´„ =====
def generate_summary(entry):
    global ai_calls_this_hour, last_reset_hour

    now = now_jst()
    if now.hour != last_reset_hour:
        ai_calls_this_hour = 0
        last_reset_hour = now.hour

    if entry.link in summary_cache:
        return summary_cache[entry.link]

    if ai_calls_this_hour >= AI_LIMIT_PER_HOUR:
        return "è¦ç´„å¤±æ•—", ["", "", ""]

    article = fetch_article_text(entry.link)
    if not article:
        return "è¦ç´„å¤±æ•—", ["", "", ""]

    prompt = f"""
ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’3è¡Œä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
ãã®å¾Œãƒã‚¤ãƒ³ãƒˆã‚’3ã¤å‡ºã—ã¦ãã ã•ã„ã€‚

{article}
"""

    try:
        response = openai.chat.completions.create(
            model="gpt-5-mini",
            messages=[{"role": "user", "content": prompt}]
        )

        text = response.choices[0].message.content.strip()
        lines = [l.strip() for l in text.split("\n") if l.strip()]

        summary = lines[0] if lines else "è¦ç´„å¤±æ•—"
        points = lines[1:4]

        while len(points) < 3:
            points.append("")

        result = (summary, points)
        summary_cache[entry.link] = result
        ai_calls_this_hour += 1
        return result

    except:
        return "è¦ç´„å¤±æ•—", ["", "", ""]

# ===== è¦ç´„ãƒ†ãƒ³ãƒ—ãƒ¬ =====
def format_summary(summary, points, url):
    bullet = "\n".join(f"ãƒ»{p}" for p in points if p)

    return (
        "ğŸ§  è¦ç´„\n\n"
        f"{summary}\n\n"
        "ğŸ‘‰ ãƒã‚¤ãƒ³ãƒˆ\n"
        f"{bullet}\n\n"
        f"ğŸ”— {url}"
    )

# ===== æŠ•ç¨¿ =====
def post_news(category, entry):
    url = WEBHOOK_IT if category == "IT" else WEBHOOK_BUSINESS
    send_webhook(url, f"{category}ãƒˆãƒ”ãƒƒã‚¯: {entry.title}\n{entry.link}")

def post_summary(category, text):
    url = WEBHOOK_IT_SUMMARY if category == "IT" else WEBHOOK_BUSINESS_SUMMARY
    send_webhook(url, text)

# ===== AI 1æ—¥æŒ¯ã‚Šè¿”ã‚Š =====
def generate_daily_summary(daily_news):
    global ai_calls_this_hour, last_reset_hour

    now = now_jst()
    if now.hour != last_reset_hour:
        ai_calls_this_hour = 0
        last_reset_hour = now.hour

    news_text = ""
    for cat in ["IT", "BUSINESS"]:
        for entry in daily_news.get(cat, []):
            news_text += f"{cat}: {entry.title}\n"

    prompt = f"""
ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å…ƒã«1æ—¥ã®æŒ¯ã‚Šè¿”ã‚Šã‚’ä½œã£ã¦ãã ã•ã„ã€‚
è§£èª¬é¢¨ã§ã€å…¨ä½“ã®æµã‚Œã¨ä»Šå¾Œã®å½±éŸ¿ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{news_text}
"""

    try:
        response = openai.chat.completions.create(
            model="gpt-5-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()

    except:
        return "æŒ¯ã‚Šè¿”ã‚Šç”Ÿæˆå¤±æ•—"

# ===== æŒ¯ã‚Šè¿”ã‚ŠæŠ•ç¨¿ =====
def post_daily_review(daily_news):
    now = now_jst().strftime("%Y-%m-%d")
    content = f"ğŸ“ 1æ—¥ã®æŒ¯ã‚Šè¿”ã‚Š ({now})\n\n"

    for cat in ["IT", "BUSINESS"]:
        entries = daily_news.get(cat, [])
        if entries:
            content += f"ã€{cat}ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘\n"
            for e in entries:
                content += f"ğŸ’¡ {e.title}\nğŸ”— {e.link}\n\n"

    content += "ã€ç·æ‹¬ã€‘\n"
    content += generate_daily_summary(daily_news)

    send_webhook(WEBHOOK_DAILY_REVIEW, content)

# ===== ä¸¦åˆ—å‡¦ç† =====
async def process_entry(category, entry):
    post_news(category, entry)
    await asyncio.sleep(random.randint(60, 120))  # ãƒ†ã‚¹ãƒˆç”¨çŸ­ç¸®
    summary, points = generate_summary(entry)
    text = format_summary(summary, points, entry.link)
    post_summary(category, text)

# ===== ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— =====
async def main_loop():
    daily_news = {"IT": [], "BUSINESS": []}
    posted = set()

    print("ğŸ” AIãƒ‹ãƒ¥ãƒ¼ã‚¹Botèµ·å‹•")
    print("ğŸ§  è¦ç´„ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•")

    while True:
        now = now_jst()

        if 6 <= now.hour < 22:
            for cat, url in FEEDS.items():
                feed = feedparser.parse(url)
                for entry in feed.entries:
                    if entry.link in posted:
                        continue
                    posted.add(entry.link)
                    daily_news[cat].append(entry)
                    asyncio.create_task(process_entry(cat, entry))

        # ãƒ†ã‚¹ãƒˆç”¨ï¼šã™ãæŒ¯ã‚Šè¿”ã‚Š
        if any(daily_news.values()):
            await asyncio.sleep(180)
            post_daily_review(daily_news)
            daily_news = {"IT": [], "BUSINESS": []}
            posted.clear()

        await asyncio.sleep(300)

# ===== å®Ÿè¡Œ =====
if __name__ == "__main__":
    asyncio.run(main_loop())
